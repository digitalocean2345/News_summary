"""
Quick offline test for content scraping system
Tests core functionality without network requests or translation
"""

from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from app.models.models import News
from app.services.scraper_config import get_selector_config, get_language_config
from bs4 import BeautifulSoup

def test_database_schema():
    """Test 1: Verify database schema has all required fields"""
    print("ğŸ“‹ Test 1: Database Schema")
    print("-" * 25)
    
    try:
        engine = create_engine("sqlite:///./news.db", echo=False)
        SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
        db = SessionLocal()
        
        # Get a sample article
        article = db.query(News).first()
        if not article:
            print("âŒ No articles in database")
            return False
        
        # Check for new translation fields
        required_fields = [
            'full_content', 'full_content_english', 'summary', 'summary_english',
            'content_language', 'source_domain', 'is_content_scraped', 
            'is_content_translated', 'is_summarized'
        ]
        
        print(f"ğŸ“° Testing article: {article.title[:30]}...")
        
        missing_fields = []
        for field in required_fields:
            if not hasattr(article, field):
                missing_fields.append(field)
        
        if missing_fields:
            print(f"âŒ Missing fields: {missing_fields}")
            return False
        else:
            print("âœ… All required fields present")
            print(f"   - Domain: {article.source_domain}")
            print(f"   - Language: {article.content_language}")
            print(f"   - Content scraped: {article.is_content_scraped}")
            return True
            
    except Exception as e:
        print(f"âŒ Database test failed: {e}")
        return False
    finally:
        db.close()

def test_selector_configs():
    """Test 2: Verify selector configurations"""
    print("\nğŸ¯ Test 2: Selector Configurations")
    print("-" * 35)
    
    try:
        domains = [
            "society.people.com.cn", 
            "world.people.com.cn", 
            "politics.people.com.cn",
            "unknown-domain.com"
        ]
        
        for domain in domains:
            config = get_selector_config(domain)
            print(f"ğŸŒ {domain}:")
            print(f"   Content: {config.content_selector}")
            print(f"   Title: {config.title_selector}")
            print(f"   Remove: {len(config.remove_selectors)} items")
        
        # Verify the updated society selector
        society_config = get_selector_config("society.people.com.cn")
        if "div.rm_txt_con p" in society_config.content_selector:
            print("âœ… Society selector updated correctly")
        else:
            print("âŒ Society selector not updated")
            return False
        
        return True
        
    except Exception as e:
        print(f"âŒ Selector config test failed: {e}")
        return False

def test_html_parsing():
    """Test 3: Test HTML parsing with sample content"""
    print("\nğŸ” Test 3: HTML Parsing")
    print("-" * 23)
    
    try:
        # Create sample HTML that mimics People's Daily structure
        sample_html = """
        <html>
        <head><title>Sample News Article</title></head>
        <body>
            <h1 class="title">æµ‹è¯•æ–°é—»æ ‡é¢˜</h1>
            <div class="rm_txt_con">
                <p>è¿™æ˜¯ç¬¬ä¸€æ®µæ–°é—»å†…å®¹ï¼ŒåŒ…å«äº†é‡è¦çš„ä¿¡æ¯ã€‚</p>
                <p>è¿™æ˜¯ç¬¬äºŒæ®µå†…å®¹ï¼Œæä¾›äº†æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚</p>
                <p>è¿™æ˜¯ç¬¬ä¸‰æ®µï¼Œæ€»ç»“äº†æ•´ä¸ªæ–°é—»äº‹ä»¶ã€‚</p>
            </div>
            <div class="ad">å¹¿å‘Šå†…å®¹</div>
        </body>
        </html>
        """
        
        soup = BeautifulSoup(sample_html, 'html.parser')
        
        # Test society selector
        config = get_selector_config("society.people.com.cn")
        content_elements = soup.select(config.content_selector)
        
        if content_elements:
            total_text = " ".join([el.get_text(strip=True) for el in content_elements])
            print(f"âœ… Extracted {len(content_elements)} paragraphs")
            print(f"   Total text: {len(total_text)} characters")
            print(f"   Preview: {total_text[:100]}...")
            
            if len(total_text) >= 50:  # Lower threshold for test
                print("âœ… Substantial content extracted")
                return True
            else:
                print("âŒ Insufficient content")
                return False
        else:
            print("âŒ No content extracted")
            return False
            
    except Exception as e:
        print(f"âŒ HTML parsing test failed: {e}")
        return False

def test_language_configs():
    """Test 4: Language configuration"""
    print("\nğŸŒ Test 4: Language Configurations")
    print("-" * 33)
    
    try:
        # Test Chinese config
        zh_config = get_language_config("zh")
        print(f"ğŸ‡¨ğŸ‡³ Chinese config:")
        print(f"   Requires translation: {zh_config['require_translation']}")
        print(f"   Translation service: {zh_config['translation_service']}")
        
        # Test English config
        en_config = get_language_config("en")
        print(f"ğŸ‡ºğŸ‡¸ English config:")
        print(f"   Requires translation: {en_config['require_translation']}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Language config test failed: {e}")
        return False

def test_api_imports():
    """Test 5: Verify API components can be imported"""
    print("\nğŸ”§ Test 5: API Component Imports")
    print("-" * 32)
    
    try:
        # Test critical imports
        from app.services.content_scraper import ContentScraper
        from app.api.content_endpoints import router
        from app.schemas.schemas import ContentScrapeRequest, ContentScrapeResponse
        
        print("âœ… ContentScraper imported")
        print("âœ… API router imported")
        print("âœ… Schema classes imported")
        
        # Test ContentScraper initialization (without network calls)
        scraper = ContentScraper()
        print("âœ… ContentScraper initialized")
        scraper.close()
        
        return True
        
    except Exception as e:
        print(f"âŒ Import test failed: {e}")
        return False

def main():
    """Run all quick tests"""
    print("ğŸš€ Quick Offline Content Scraping Tests")
    print("=" * 42)
    
    tests = [
        ("Database Schema", test_database_schema),
        ("Selector Configs", test_selector_configs),
        ("HTML Parsing", test_html_parsing),
        ("Language Configs", test_language_configs),
        ("API Imports", test_api_imports)
    ]
    
    results = []
    for test_name, test_func in tests:
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"âŒ {test_name} crashed: {e}")
            results.append((test_name, False))
    
    # Summary
    print("\nğŸ“Š TEST SUMMARY")
    print("=" * 15)
    
    passed = 0
    for test_name, result in results:
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"{status} {test_name}")
        if result:
            passed += 1
    
    print(f"\nğŸ¯ {passed}/{len(tests)} tests passed")
    
    if passed == len(tests):
        print("ğŸ‰ ALL TESTS PASSED - Content scraping system ready!")
    else:
        print("âš ï¸ Some tests failed - check configuration")

if __name__ == "__main__":
    main() 